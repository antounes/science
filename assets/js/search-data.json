{
  
    
        "post0": {
            "title": "Classifying Bicycle Spare Parts with Deep Learning: A Trial",
            "content": "This personal research work should help me getting a sound understanding of how convolutional neural networks work under the hood. Notebooks help mixing computer science practice and deep learning theory. Note: This notebook is implemented with the fastai library, built atop PyTorch. Experiments are greatly inspired from Howard&#39;s and Gugger&#39;s book Deep Learning for Coders with fastai and PyTorch. . Introduction . The goal here is to build a classifier for distinguishing between bicycle spare parts. When looking for parts, one of the most tedious tasks is to differentiate between different versions of a given part called a cassette. The cassette is a block of sprockets located on the bicycle rear wheel and ensuring the transmission of the power applied on the pedals to the rear wheel via the chain, hence making the bike moving forward. Most today&#39;s bicycle drivetrains use either 10-, 11- or 12-sprocket cassettes. Distinguishing between these at first glance is not easy, as can be seen below. In fact what we just see is just a mass of cogs. . . Distinguishing between types of cassettes is crucial though, because not all cassettes can be used with all chains and all shifters on a bicycle. 10-speed cassettes go with 10-speed drivetrains, etc. . On could argue that it&#39;s just about counting the sprockets, or reading the numbers written on the lockring (the smallest and darkest ring of the cassette), but it&#39;s not always as easy, especially with greasy or muddy parts, or even with old ones where nothing can be read anymore. . Let&#39;s assess if such objects are understandable and can be represented in such a manner that a neural network can distinguish between their types. . Gathering Data . This notebook uses tilities provided by fast.ai authors, namely the fastbook library. This library comes with classes and modules that will help us setting up deep learing models. . fastai authors have built a tool that allows to download images from search engines, thus ensuring we can build our image dataset. Here we&#39;ll be using the most up-to-date version of the class, scrapping images from DuckDuckGo search results. Latest version and tutorial can be found on fast.ai book&#39;s website. For the sake of time-saving and reproducibility, we&#39;ll limit the dataset to 100 images of each type of cassette we&#39;re trying to identify. . Images are scrapped from the Internet and stored in a folder created for each type of cassette. Some additional steps consist of checking if all images are in the create folders and if there are no corrupted files, since they&#39;ve been downloaded from the Internet. Corrupted files are eventually discarded. . Download complete. 296 downloaded files. 1 corrupted file(s). . Let&#39;s have a look at a some images taken at random from the downloaded dataset. . Clearly there&#39;s no other way of distinguishing between cassette types than counting the number of sprockets. Following steps hopefully will lead us to build a model that will wisely represent each image to be able to identify each class. . Preparing Data for Training The Network . Creating Suitable Data Structures . Convolutional neural networks accept images as inputs. They won&#39;t accept jpg, png, or any other image file format though. Generally speaking, when developing deep learning models, our first thoughts must concern data representation, be it technically or conceptually. . Technically, models accept numbers. Deal with it. We&#39;ll have to find a way of passing our downloaded images to the model we&#39;ll build in a way the model will be able to process them and produce outputs from them. Conceptually, before diving headfirst in code, carefully thinking of a way of representing raw data can save hours and prevent headaches that could arise when dealing with neural network architecture considerations. . We must also define how to create the sets used for training and evaluating our model. Here, the variable to predict (the dependent variable) is a category of cassette $-$ 10-, 11- or 12-speed. The inputs used by the model for outputing classifications (the independent variables) are cassette images. Building the training and validation sets must be carried out carefully, and significant performance improvements can come only from a wise selection of training and validation examples for feeding a network. Here we&#39;ll perform random splitting of the images, with a fraction of 20% being used as validation set. . Images downloaded are of different sizes. We can have a look at the size distribution below (for the sake of clarity, only sizes counting more than 10 images have been plotted here). This is a problem since we won&#39;t feed our network one image at a time, but rather batches of images (technically we&#39;re feeding mini-batches, but this will be discussed later). Before grouping it into a structure that can be sliced into such mini-batches, we need to resize the images to the same size. . Once all these preparation steps have been defined and carried out, we&#39;re ready to build our data structures and provide them to the network. We can look at a few images from the training and validation batches we just created. . Let&#39;s pause a second for an important word here: resizing images will somewhat modify the reality. The model will be fed with images that may be cropped, stretched, etc. . A very crucial point in machine learning (and consequently in deep learning) is that a models cannot perform on concepts they haven&#39;t been trained on. Feeding a neural network with black and white images and then trying to produce outputs on never-seen coloured images can only result in poor performance. The goal of deep learning is to find useful representations of data, be it in a humanly understandable space or not. Models cannot invent representations while they haven&#39;t been trained on, they&#39;re just searching for better and more explainable representations of the input data. That&#39;s why data preparation is maybe the most important point in building deep learning models. . Data Augmentation .",
            "url": "https://antounes.github.io/science/2021/12/30/draft-first-post.html",
            "relUrl": "/2021/12/30/draft-first-post.html",
            "date": " • Dec 30, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "about",
          "content": "I’m a research data scientist navigating the field of what’s for show called AI. In fact, I’m keen on probability theory, linear algebra, machine learning and deep learning.I love approaching problems in a rigorously scientific manner, finding beautiful solutions and explaining them well. This blog is my workbook, it’s been continuously updated since December 2021 so as to keep a track of my research progress. .",
          "url": "https://antounes.github.io/science/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  
  

  
  

  
  

  
  

  
      ,"page8": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://antounes.github.io/science/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}